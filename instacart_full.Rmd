---
title: "instacart_full"
author: "Thalia Taffe"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r}
library(dplyr)
library(ggplot2)
library(ggwordcloud)
library(tidytext)
library(topicmodels)
library(tidyr)
```

```{r}
seedd = 542
theme_set(theme_bw())

aisles <- read.csv("aisles.csv")
departments <- read.csv("departments.csv")
order_products <- read.csv("order_products__train.csv")
orders <- read.csv("orders.csv")
products <- read.csv("products.csv")
```

```{r, warning=FALSE}
orders <- orders %>% filter(eval_set == "train")

# merge aisles on products (aisle id) and departments on products (department id)
products <- inner_join(aisles, products, by = "aisle_id")
products <- inner_join(departments, products, by = "department_id")

# merge orders and order_products (on order id)
orders <- inner_join(orders, order_products, by = "order_id") %>%
  dplyr::select(!eval_set)

# merge both datasets ()
orders <- inner_join(orders, products, by = "product_id")
orders <- orders %>% 
  filter(!department == "missing" & days_since_prior_order > 0)
```


```{r}
# select random subset of 2000 id
set.seed(seedd)

ids <- unique(orders$user_id) %>% sample(500)
orders <- orders %>% filter(user_id %in% ids)

sum(unique(orders$order_id))
sum(unique(orders$user_id))
orders
```


```{r}
## Checking for missing values

# count the number of missing values in each column
missing_counts <- colSums(is.na(orders))

# create a table with the missing value counts
missing_table <- data.frame(
  column_names = names(missing_counts),
  missing_count = missing_counts,
  row.names = NULL
)

missing_table
```

## EDA

## 1.The most commonly bought products and its respective department 
```{r}

# group by department and product
dept_prod_counts <- orders %>%
  group_by(department, product_name) %>%
  filter(reordered == 1) %>%
  summarise(prod_count = n()) %>%
  ungroup()

# select top 10 products for each department
top_prod <- dept_prod_counts %>%
  group_by(department) %>%
  filter(prod_count >= 7) 

top_prod <- top_prod %>%  arrange(desc(prod_count)) 
top_prod$department <- factor(top_prod$department)
top_prod %>% glimpse()

top_prod_produce <- top_prod %>% filter(department == 'produce')
top_prod_else <- top_prod %>% filter(department != 'produce')

top_prod_produce %>%
  ggplot(aes(x =prod_count, y = reorder(product_name,-prod_count), fill = department)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ department, scales = "free",ncol = 2) 

top_prod_else %>%
  ggplot(aes(x =prod_count, y = reorder(product_name,-prod_count), fill = department)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ department, scales = "free",ncol = 2) 
```


## 2. The most common aisles which are reordered from
```{r}
aisle_reorder <- orders %>%
                filter(reordered == 1) %>%
                group_by(department,aisle) %>% 
                summarise(num_reorders = n()) %>% 
                arrange(desc(num_reorders)) %>%
                ungroup() %>%
                glimpse()
                
        
aisle_reorder%>%
slice_max(num_reorders, n = 50) %>%
ggplot(aes(label = aisle, size = num_reorders, color = department))+
  geom_text_wordcloud() +
  scale_size_area(max_size = 10)
```


## 3

```{r}
orders %>% 
  group_by(user_id) %>% 
  ggplot(aes(x = days_since_prior_order)) + geom_histogram() + xlab("Days Since Prior Order")
```


## 4
```{r}
orders %>% 
  #group_by(user_id) %>% 
  ggplot(aes(x = add_to_cart_order)) + geom_bar() + facet_wrap(~department)
```


```{r}
shopper_type <- function(df){
  convenience <- c("frozen", "bakery", "beverages", "babies", "pets", 
                 "snacks", "household", "personal care", "alcohol", "other")
  products <- df %>% group_by(user_id) %>% count()
  df$purpose <- "Unknown"
  c <- 0
  s <- 0
  
  x <- 1
  while (x <= length(df$department)){
    if (df$department[x] %in% convenience){
      c <- c + 1
      } else {
        s <- s + 1
    }
    if (c > s){
      df$purpose[x] <- "Convenience"
      } else {
        df$purpose[x] <- "Shopping"
      }
    x = x + 1
  }
  i <- 1
  while (i <= 500){
    if (products$n[i] <= 7){
      user <- products$user_id[i]
      df$purpose[df$user_id == user] <- "Convenience"
    }
    i <- i + 1
  }
  return(df)
}

orders <- shopper_type(orders)
```

#5
```{r}
#ggplot(orders, aes(x = purpose, groupby = user_id)) + geom_bar()
q <- orders %>% group_by(order_id) %>% count()
o <- orders %>% group_by(user_id) %>% count()  %>% rename(Products = n)
dim(o)[1]
dim(q)[1]
# same length = no repeat users

o %>% ggplot(aes(x = Products, fill = Products <= 7)) + geom_histogram() + xlab("Number of Products in Order") + ggtitle("Distribution of Number of Products Ordered") + scale_fill_manual(values = c("navy blue", "light blue"), labels = c("Shopping", "Convenience"))
orders %>% dplyr::count(purpose)
```

```{r}
# bag of words
order_sub <- orders %>% 
  select(department, product_name) #%>% 
  #mutate(department_id = as.integer(department_id))

(order_tidy <- order_sub %>% unnest_tokens(word, product_name))

order_counts <- order_tidy %>% 
  group_by(word, department) %>%
  summarize(term_frequency = n(), .groups = "drop") %>%
  arrange(desc(term_frequency))

order_counts
```

#6

```{r, warning = FALSE}
# all department wordcloud

idf_department <-order_counts %>% 
  group_by(department, word) %>%
  summarize(term_frequency = sum(term_frequency)) %>%
  bind_tf_idf(word, department, term_frequency) %>% 
  arrange(desc(tf_idf))

idf_department

idf_department %>% 
  slice_max(tf_idf, n = 8, with_ties = FALSE) %>%
  ggplot() + geom_text_wordcloud_area(aes(label = word, size = tf_idf)) +
  facet_wrap(~department) + scale_size_area(max_size = 4) 
```

## 7 Hourly order pattern
```{r}
orders %>% group_by(order_hour_of_day) %>% summarize(count = n()) %>% mutate(percentage = count/sum(count)) %>% ggplot(aes(x = as.factor(order_hour_of_day), y = percentage)) + geom_col() + labs(y = "Percentage of Order", title = "Hourly Orders")
```


# Topic Modeling
```{r}

# Convert order data to product data
products <- orders %>%
  ungroup() %>%
  select(order_id, product_name) 

# Create document-term matrix
prod_dtm <- products %>%
  count(order_id, product_name) %>%
  cast_tdm(order_id,product_name, n)

lda <- LDA(prod_dtm, k = 5, control = list(seed = 123))

#Word distribution associated with each topic
lda_topics <- tidy(lda, matrix = "beta")
head(lda_topics, n = 20)

#Most common word combinations
lda_topics %>% slice_max(beta, n = 10)

#Most common words in the topics
top_terms <- lda_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 8) %>% 
  mutate(topic = factor(topic))

topic_names <- c("Salads-I",
                 "Cooking",
                 "Salads-II",
                 "Smoothie",
                 "Breakfast Mix")

top_terms %>% 
  mutate(topic =  forcats::as_factor(topic_names[topic])) %>%
  ggplot(aes(x = beta, y = term, fill = topic)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic,scale = "free_y",ncol = 2) +
  xlab("Relative Frequency")
```


# Market Basket Analysis  
```{r}
library(arules)

#Convert the data to a transaction format
transactions <- orders %>%
 group_by(user_id,order_number) %>%
 summarise(products = list(as.character(product_name)))

##Performing market basket analysis using the Apriori algorithm
#rules <- apriori(transactions$products, parameter = list(support = 0.001, confidence = 0.8, minlen = 2,maxlen = 4))
#save(rules, file = "saved_rules.RDA")
load("saved_rules.RDA")

##Sorting
#sorted_rules <- sort(rules, by = "support", decreasing = TRUE)
#save(sorted_rules, file = "sorted_rules.RDA")
load("sorted_rules.RDA")

##Removing Redundant rules
#assoc_rules <- sorted_rules[1:5000]
#subset.rules <- which(colSums(is.subset(subset_rules, subset_rules)) > 1) 
#length(subset.rules)  
#subset.association.rules. <- assoc_rules[-subset.rules]


# Print the top 10 rules
#top10 <- inspect(head(subset.association.rules., n = 10)) 
#save(top10, file = "top10_rules.RDA")
load("top10_rules.RDA")
top10

```



# Train - Test Split
````{r}
library(rsample)
set.seed(seedd)

#Making the response variable binary before splitting
orders$purpose <- ifelse(orders$purpose == "Shopping", 1, 0)
orders <- orders %>% mutate(purpose = as.factor(purpose))
split <- initial_split(orders, prop = 0.8, strata = purpose)
train <- training(split)
test <- testing(split)
```


## Modeling - Logistic Regression

## 1. Logit
```{r}

formula <- purpose ~ order_dow + order_hour_of_day + days_since_prior_order + add_to_cart_order + reordered + department

fit_logit <- glm(formula = formula, data = train, family = binomial(link = "logit") )

summary(fit_logit)
```

```{r}
prediction_logit <- fit_logit %>% predict(test, type = "response")
```

## 2. Probit

```{r}
fit_probit <- glm(formula = formula, data = train, family = binomial(link = "probit") )
summary(fit_probit)

```

```{r}
prediction_probit <- fit_probit %>% predict(test, type = "response")
```


## 3. LASSO
```{r}
library(glmnet)
library(modelr)

y <- train %>% select(purpose) %>% as.matrix
  
order_x <- train %>%
  modelr::model_matrix(purpose ~ 
                          order_dow +
                          order_hour_of_day +
                          days_since_prior_order + 
                          add_to_cart_order +
                          reordered + 
                          department 
                          ) 
order_x %>% glimpse()
```


```{r}
fit_lasso <- glmnet(x = order_x,
                    y = y, 
                    family = "binomial")

coef(fit_lasso, s = 0.01)
```


```{r}
lasso_test <- test %>%
  modelr::model_matrix(purpose ~ 
                         order_dow+
                         order_hour_of_day+
                         days_since_prior_order+
                          add_to_cart_order +
                          reordered +
                          department 
                          ) 
lasso_test_matrix <- as.matrix(lasso_test)
prediction_lasso <-  predict(fit_lasso, newx = lasso_test_matrix, s = 0.01)
```


## 4. Random Forest

```{r}
library(ranger)
library(tidymodels)
set.seed(seedd)

default_rf <- rand_forest() %>% 
  set_mode("classification") %>% 
  set_engine("ranger")

drf_fit <- default_rf %>% fit(purpose ~ ., data = train) %>% extract_fit_engine()
drf_fit

drf_pred <- predict(drf_fit, test, type = "response")

```


## 5. Optimized Random Forest

```{r}
set.seed(seedd)

trees <- seq(100, 1000, 100)
pred <- c(2, 3)

best_rf_error <- 1
error_list <- list()

for (t in trees){
  for (p in pred){
    rf_model <- rand_forest(mtry = p, trees = t) %>% 
      set_mode("classification") %>% 
      set_engine("ranger")
    rf_wrkflow_fit <- workflow() %>% 
      add_model(rf_model) %>%
      add_formula(purpose ~ .) %>% fit(train)
    err <- rf_wrkflow_fit$fit$fit$fit$prediction.error
    error_list <- append(error_list, err)
    if (err < best_rf_error){
      best_rf_error = err
      best_model = rf_wrkflow_fit
    }
  }
}
best_model
#error_list

best_rf_pred_class <- best_model %>% predict(test, type = "class")
best_rf_pred_prob <- best_model %>% predict(test, type = "prob")
best_rf_pred <- bind_cols(best_rf_pred_class, best_rf_pred_prob)
```





# Model Selection - ROC

```{r}
library(pROC)
roc_logit = roc(test$purpose ~ prediction_logit, plot = TRUE, print.auc = TRUE,main ="ROC Curve - Logit ")

roc_probit = roc(test$purpose ~ prediction_probit, plot = TRUE, print.auc = TRUE, main ="ROC Curve - Probit ")

roc_lasso = roc(test$purpose ~ prediction_lasso, plot = TRUE, print.auc = TRUE, main ="ROC Curve - Lasso")

roc_rand_forest <- roc(test$purpose ~ drf_pred$predictions[,2], plot = TRUE, print.auc = TRUE, main = "ROC Curve - Random Forest")

roc_optim_rand_forest <- roc(test$purpose ~ best_rf_pred$.pred_1, plot = TRUE, print.auc = TRUE, main = "ROC Curve - Optimized Random Forest")
```


# Model Assessment

# 1.
```{r}
table(test$purpose, best_rf_pred$.pred_class)/1310*100
```


```{r}
set.seed(seedd)

orders_bootstrap <- train %>% bootstraps(times = 100)
bootstrap_fit_orders <- fit_resamples(best_model, orders_bootstrap)
#bootstrap_fit_orders$.metrics
```



```

